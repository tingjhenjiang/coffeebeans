{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Compile darknet YOLOv4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import tensorflow as tf\r\n",
    "if tf.test.gpu_device_name():\r\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\r\n",
    "else:\r\n",
    "    print(\"Please install GPU version of TF\")\r\n",
    "workingdir = os.getcwd()\r\n",
    "darknetdir = os.path.join(workingdir,'darknet')\r\n",
    "print(workingdir)\r\n",
    "print(os.environ)"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1621494522198
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# change makefile to have GPU and OPENCV enabled\r\n",
    "%cd {darknetdir}\r\n",
    "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\r\n",
    "!sed -i 's/GPU=0/GPU=1/' Makefile\r\n",
    "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\r\n",
    "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\r\n",
    "!sed -i 's/AVX=0/AVX=1/' Makefile\r\n",
    "!sed -i 's/OPENMP=0/OPENMP=1/' Makefile\r\n",
    "!sed -i 's/DEBUG=0/DEBUG=1/' Makefile\r\n",
    "!sed -i 's/LIBSO=0/LIBSO=1/' Makefile"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xym8_m8CIyXK",
    "outputId": "211ca614-dea9-4b1e-f7fd-b3d115f5e105"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# verify CUDA\r\n",
    "!/usr/local/cuda/bin/nvcc --version"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Mon_May__3_19:15:13_PDT_2021\n",
      "Cuda compilation tools, release 11.3, V11.3.109\n",
      "Build cuda_11.3.r11.3/compiler.29920130_0\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "5uloUwmUKF05",
    "outputId": "f8af3e34-eba8-4692-cb28-4482679c56b4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make darknet (builds darknet so that you can then use the darknet executable file to run or train object detectors)\r\n",
    "!make"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "q2Jjv0yRKLPe",
    "outputId": "29bef5cb-38d2-4f18-e5c5-281ea38407c3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training\r\n",
    "./darknet detector train /opt/mnt/code-391ff5ac-6576-460f-ba4d-7e03433c68b6/Users/O/coffeebeans/darknet/data/backup/3classbeans_w640h640_20210608/obj.data /opt/mnt/code-391ff5ac-6576-460f-ba4d-7e03433c68b6/Users/O/coffeebeans/darknet/data/backup/3classbeans_w640h640_20210608/yolov4-tiny-obj.cfg /opt/mnt/code-391ff5ac-6576-460f-ba4d-7e03433c68b6/Users/O/coffeebeans/darknet/data/yolov4-tiny.conv.29 -dont_show -map -gpus 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.chdir(workingdir)\r\n",
    "import copy, random, subprocess\r\n",
    "from IPython.display import display\r\n",
    "import cv2\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import commonsettings\r\n",
    "\r\n",
    "baseConfigFilenames = commonsettings.generatePaths(specificProjName = '3classbeans_yolo4tiny_filtered_w512h512_20210711')\r\n",
    "\r\n",
    "trainingCommand = [\"./darknet\", 'detector', 'train',\r\n",
    "                   baseConfigFilenames['objDataFileName']['display'],\r\n",
    "                   baseConfigFilenames['modelCfgFileName']['display'],\r\n",
    "                   baseConfigFilenames['pretrainedWeightFileName']['display'],\r\n",
    "                   '-dont_show','-map','-gpus','0',\r\n",
    "                   '>>', baseConfigFilenames['trainingRecordsFileName']['display'],\r\n",
    "                  ]\r\n",
    "continuousTrainingCommand = copy.deepcopy(trainingCommand)\r\n",
    "continuousTrainingCommand[5] = baseConfigFilenames['backupLastWeightFileName']['display']\r\n",
    "trainingCommand_str = \" \".join(trainingCommand)\r\n",
    "continuousTrainingCommand_str = \" \".join(continuousTrainingCommand)\r\n",
    "print(trainingCommand_str)\r\n",
    "print(continuousTrainingCommand_str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "./darknet detector train /opt/mnt/code-391ff5ac-6576-460f-ba4d-7e03433c68b6/Users/O/coffeebeans/darknet/data/backup/3classbeans_yolo4_filtered_densenet201_w512h512_20210617/obj.data /opt/mnt/code-391ff5ac-6576-460f-ba4d-7e03433c68b6/Users/O/coffeebeans/darknet/data/backup/3classbeans_yolo4_filtered_densenet201_w512h512_20210617/densenet201_yolov4.cfg /opt/mnt/code-391ff5ac-6576-460f-ba4d-7e03433c68b6/Users/O/coffeebeans/darknet/data/backup/3classbeans_yolo4_filtered_densenet201_w512h512_20210617/densenet201.weights -dont_show -map -gpus 0"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#handling chart\r\n",
    "from shutil import copyfile\r\n",
    "\r\n",
    "yolov4ModelConfigStorePath = os.path.dirname(baseConfigFilenames['objDataFileName']['orig'])\r\n",
    "#yolov4ModelCharts = [f for f in os.listdir(yolov4ModelConfigStorePath) if f.find(\".png\")!=-1]\r\n",
    "trySaveChartN = 1\r\n",
    "while True:\r\n",
    "    checkIfChartSavedFileName = 'chart'+'{0:02d}'.format(trySaveChartN)+'.png'\r\n",
    "    checkIfChartSavedFilePath = os.path.join(yolov4ModelConfigStorePath, checkIfChartSavedFileName)\r\n",
    "    if os.path.isfile(checkIfChartSavedFilePath):\r\n",
    "        print(\"skipping \"+checkIfChartSavedFilePath)\r\n",
    "        trySaveChartN += 1\r\n",
    "    else:\r\n",
    "        print(\"檔案未存在，存檔為。\"+checkIfChartSavedFileName)\r\n",
    "        copyfile(os.path.join(darknetdir, 'chart.png'), checkIfChartSavedFilePath)\r\n",
    "        break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%cd {darknetdir}\r\n",
    "!{trainingCommand_str}"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " total_bbox = 873, rewritten_bbox = 1.145475 % \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 30 Avg (IOU: 0.000000), count: 1, class_loss = 545.985596, iou_loss = 0.000000, total_loss = 545.985596 \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 37 Avg (IOU: 0.296582), count: 125, class_loss = 1813.044189, iou_loss = 85.249512, total_loss = 1898.293701 \n",
      " total_bbox = 998, rewritten_bbox = 1.002004 % \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 30 Avg (IOU: 0.000000), count: 1, class_loss = 559.101440, iou_loss = 0.000000, total_loss = 559.101440 \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 37 Avg (IOU: 0.311379), count: 339, class_loss = 1867.959595, iou_loss = 176.663696, total_loss = 2044.623291 \n",
      " total_bbox = 1337, rewritten_bbox = 0.747943 % \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 30 Avg (IOU: 0.000000), count: 1, class_loss = 553.809692, iou_loss = 0.000000, total_loss = 553.809692 \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 37 Avg (IOU: 0.301477), count: 89, class_loss = 1833.329590, iou_loss = 28.780640, total_loss = 1862.110229 \n",
      " total_bbox = 1426, rewritten_bbox = 0.771388 % \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 30 Avg (IOU: 0.000000), count: 1, class_loss = 554.698242, iou_loss = 0.000000, total_loss = 554.698242 \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 37 Avg (IOU: 0.299311), count: 78, class_loss = 1832.134521, iou_loss = 23.576538, total_loss = 1855.711060 \n",
      " total_bbox = 1504, rewritten_bbox = 0.997340 % \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 30 Avg (IOU: 0.000000), count: 1, class_loss = 545.190430, iou_loss = 0.000000, total_loss = 545.190430 \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 37 Avg (IOU: 0.371859), count: 59, class_loss = 1823.659790, iou_loss = 33.252686, total_loss = 1856.912476 \n",
      " total_bbox = 1563, rewritten_bbox = 0.959693 % \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 30 Avg (IOU: 0.000000), count: 1, class_loss = 543.290649, iou_loss = 0.000000, total_loss = 543.290649 \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 37 Avg (IOU: 0.343741), count: 156, class_loss = 1839.285400, iou_loss = 95.800903, total_loss = 1935.086304 \n",
      " total_bbox = 1719, rewritten_bbox = 0.930774 % \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 30 Avg (IOU: 0.000000), count: 1, class_loss = 549.991211, iou_loss = 0.000000, total_loss = 549.991211 \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 37 Avg (IOU: 0.319126), count: 139, class_loss = 1846.808472, iou_loss = 110.041504, total_loss = 1956.849976 \n",
      " total_bbox = 1858, rewritten_bbox = 1.022605 % \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 30 Avg (IOU: 0.000000), count: 1, class_loss = 558.033203, iou_loss = 0.000000, total_loss = 558.033203 \n",
      "v3 (iou loss, Normalizer: (iou: 0.07, obj: 1.00, cls: 1.00) Region 37 Avg (IOU: 0.323488), count: 149, class_loss = 1853.755737, iou_loss = 110.074219, total_loss = 1963.829956 \n",
      " total_bbox = 2007, rewritten_bbox = 0.946687 % \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testPredictImage = random.choice(baseConfigFilenames['allTakenImages']['display'])\r\n",
    "\r\n",
    "testProcessPredictRunCommand = copy.deepcopy(trainingCommand)\r\n",
    "testProcessPredictRunCommand[2] = 'test'\r\n",
    "testProcessPredictRunCommand.append(testPredictImage)\r\n",
    "testProcessPredictRunCommand[4] = baseConfigFilenames['modelCfgFileNameInTesting']['orig']\r\n",
    "testProcessPredictRunCommand[5] = baseConfigFilenames['backupBestWeightFileName']['orig']\r\n",
    "testProcessPredictRunCommand_str = \" \".join(testProcessPredictRunCommand)\r\n",
    "print(testProcessPredictRunCommand_str)\r\n",
    "#!./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights data/person.jpg\r\n",
    "%cd {darknetdir}\r\n",
    "!{testProcessPredictRunCommand_str}\r\n",
    "commonsettings.imShow(testPredictImage, cvtColor=True)\r\n",
    "commonsettings.imShow('predictions.jpg')\r\n",
    "%cd {workingdir}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Prediction in python"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "from commonsettings import *\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "import cv2\r\n",
    "workingdir = os.getcwd()\r\n",
    "darknetdir = os.path.join(workingdir,'darknet')\r\n",
    "baseConfigFilenames = generatePaths()\r\n",
    "os.chdir(darknetdir)\r\n",
    "import darknet\r\n",
    "#import darknet_images\r\n",
    "### baseConfigFilenames\r\n",
    "network, class_names, class_colors = darknet.load_network(\r\n",
    "        baseConfigFilenames['modelCfgFileNameInTesting']['orig'],\r\n",
    "        baseConfigFilenames['objDataFileName']['orig'],\r\n",
    "        baseConfigFilenames['backupBestWeightFileName']['orig'],\r\n",
    "        batch_size=64\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def image_detection(image_path, network, class_names, class_colors, thresh):\r\n",
    "    # Darknet doesn't accept numpy images.\r\n",
    "    # Create one with image we reuse for each detect\r\n",
    "    width = darknet.network_width(network)\r\n",
    "    height = darknet.network_height(network)\r\n",
    "    darknet_image = darknet.make_image(width, height, 3)\r\n",
    "    \r\n",
    "    isfile = False if str(type(image_path)).find(\"ndarray\")!=-1 else True\r\n",
    "    image = cv2.imread(image_path) if isfile else image_path\r\n",
    "    origShape = image.shape\r\n",
    "    \r\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n",
    "    image_resized = cv2.resize(image_rgb, (width, height),\r\n",
    "                               interpolation=cv2.INTER_LINEAR)\r\n",
    "\r\n",
    "    darknet.copy_image_from_bytes(darknet_image, image_resized.tobytes())\r\n",
    "    detections = darknet.detect_image(network, class_names, darknet_image, thresh=thresh)\r\n",
    "    scaleXfactor = 1/width*origShape[1]\r\n",
    "    scaleYfactor = 1/height*origShape[0]\r\n",
    "    detectionsAdjusted = []\r\n",
    "    for detection in detections:\r\n",
    "        label, confidence, bbox = detection\r\n",
    "        x_center, y_center, w, h = bbox\r\n",
    "        left = int(round(x_center - (w / 2)))/origShape[1]*100\r\n",
    "        top = int(round(y_center - (h / 2)))/origShape[0]*100\r\n",
    "        w = w/width*100\r\n",
    "        h = h/height*100\r\n",
    "        detectionsAdjusted.append( {'label':label, 'confidence':confidence, 'bbox':[left,top,w,h] } )\r\n",
    "    darknet.free_image(darknet_image)\r\n",
    "    image = darknet.draw_boxes(detections, image_resized, class_colors)\r\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n",
    "    returnDict = {'detections':detections, 'detectionsAdjusted':detectionsAdjusted, 'shape':(width, height), 'origshape':origShape}\r\n",
    "    returnDict['image'] = image\r\n",
    "    return returnDict\r\n",
    "\r\n",
    "argThresh = 0.25\r\n",
    "\r\n",
    "with open(os.path.join(workingdir,'labelstudioMLSimulateInput.json'), 'r') as fp:\r\n",
    "    requestsdata = json.load(fp)\r\n",
    "    tasks = requestsdata['tasks']\r\n",
    "\r\n",
    "results = []\r\n",
    "\r\n",
    "for task in tasks:\r\n",
    "    sendInImg = task['data']['image']\r\n",
    "    sendInImg = os.path.basename(task['data']['image'])\r\n",
    "    sendInImg = [f for f in baseConfigFilenames['allTakenImages']['orig'] if f.find(sendInImg)!=-1][0]\r\n",
    "    image_name = sendInImg\r\n",
    "    image = cv2.imread(image_name)\r\n",
    "    detectionsResult = image_detection(\r\n",
    "                image, network, class_names, class_colors, argThresh\r\n",
    "                )\r\n",
    "    rectanglePredResults = detectionsResult['detectionsAdjusted']\r\n",
    "    rectangles = []\r\n",
    "    for key,rectanglePredResult in enumerate(rectanglePredResults):\r\n",
    "        rectangles.append( {\r\n",
    "            'original_width': detectionsResult['shape'][0],\r\n",
    "            'original_height': detectionsResult['shape'][1],\r\n",
    "            'image_rotation': 0,\r\n",
    "            'value': {\r\n",
    "                'x': rectanglePredResult['bbox'][0],\r\n",
    "                'y': rectanglePredResult['bbox'][1],\r\n",
    "                'width': rectanglePredResult['bbox'][2],\r\n",
    "                'height': rectanglePredResult['bbox'][3],\r\n",
    "                'rotation': 0,\r\n",
    "                'rectanglelables': ['UnlabelledBean'],\r\n",
    "                'confidence': rectanglePredResult['confidence']\r\n",
    "            },\r\n",
    "            'id': '',\r\n",
    "            'from_name': '',\r\n",
    "            'to_name': '',\r\n",
    "            'type': 'rectanglelabels'\r\n",
    "        })\r\n",
    "    results.append({\r\n",
    "        'result': rectangles\r\n",
    "    })\r\n",
    "display(results)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "YOLOv4_Tutorial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "python3 datascience ready",
   "language": "python",
   "name": "python3_datascience_ready"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}